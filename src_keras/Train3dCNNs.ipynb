{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution3D, MaxPooling3D, Convolution2D, AveragePooling2D, MaxPooling2D, ZeroPadding3D, ZeroPadding2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "import operator\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import keras\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "from models_keras import CNNT5_3D, LeNet3d, VGG11_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = 'D1'  # or 'D2'\n",
    "\n",
    "train_non = pd.read_csv('/home.stud/dobkomar/luna_keras/LUNA16Challege/dataprocess/data/train_data_0_{}.csv'.format(dataset_config))\n",
    "val_non = pd.read_csv('/home.stud/dobkomar/luna_keras/LUNA16Challege/dataprocess/data/val_data_0_{}.csv'.format(dataset_config))\n",
    "train_nod = pd.read_csv('/home.stud/dobkomar/luna_keras/LUNA16Challege/dataprocess/data/train_data_1.csv')\n",
    "val_nod = pd.read_csv('/home.stud/dobkomar/luna_keras/LUNA16Challege/dataprocess/data/val_data_1.csv')\n",
    "\n",
    "candidates_train = pd.concat([train_non, train_nod])\n",
    "candidates_val = pd.concat([val_non, val_nod])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 3-D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488605e337264533913b7422169e8acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba624103c3748bbbb07b4af70129edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = [], []\n",
    "X_test, Y_test = [], []\n",
    "train_mean, val_mean = [], []\n",
    "\n",
    "train_names, val_names = [], []\n",
    "\n",
    "for row in tqdm(candidates_train.iterrows()):\n",
    "    image = row[1]\n",
    "    y_class = int(image['class'])\n",
    "    lung_img = np.load(image['filename'])\n",
    "    if lung_img.shape[0] == 32:\n",
    "        X = lung_img.reshape((32, 32,32))\n",
    "        train_mean.append(np.mean(X))\n",
    "        if np.mean(X) > 1:\n",
    "            X_train.append(X.reshape((32, 32, 32, 1))), Y_train.append(y_class)\n",
    "            train_names.append(image['filename'])\n",
    "            \n",
    "for row in tqdm(candidates_val.iterrows()):\n",
    "    image = row[1]\n",
    "    y_class = int(image['class'])\n",
    "    lung_img = np.load(image['filename'])\n",
    "    if lung_img.shape[0] == 32:\n",
    "        X = lung_img.reshape((32, 32, 32))\n",
    "        val_mean.append(np.mean(X))\n",
    "        if np.mean(X) > 1:\n",
    "            X_test.append(X.reshape((32, 32, 32, 1))), Y_test.append(y_class)\n",
    "            val_names.append(image['filename'])\n",
    "\n",
    "\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, 2)\n",
    "Y_test = np_utils.to_categorical(Y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30436, 32, 32, 32, 1),\n",
       " (30436, 2),\n",
       " (16706, 32, 32, 32, 1),\n",
       " (16706, 2),\n",
       " 30436,\n",
       " 16706)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape, len(train_names), len(val_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57.18506, 60.40257, 57.5367, 60.73366)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some statistics on data\n",
    "np.mean(X_train), np.std(X_train), np.mean(X_test), np.std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range changing\n",
    "# [-1, 1]\n",
    "# X_train_range = X_train*np.std(X_train)+np.mean(X_train)\n",
    "# X_test_range = X_test*np.std(X_test)+np.mean(X_test)\n",
    "# [0, 1]\n",
    "X_train_range = (X_train-np.mean(X_train))/np.std(X_train)\n",
    "X_test_range = (X_test-np.mean(X_test))/np.std(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30436 samples, validate on 16706 samples\n",
      "Epoch 1/30\n",
      "30436/30436 [==============================] - 26s 866us/step - loss: 0.5039 - acc: 0.7590 - val_loss: 0.4176 - val_acc: 0.8082\n",
      "Epoch 2/30\n",
      "30436/30436 [==============================] - 25s 831us/step - loss: 0.3737 - acc: 0.8395 - val_loss: 0.3268 - val_acc: 0.8565\n",
      "Epoch 3/30\n",
      "30436/30436 [==============================] - 25s 819us/step - loss: 0.2950 - acc: 0.8805 - val_loss: 0.2795 - val_acc: 0.8850\n",
      "Epoch 4/30\n",
      "30436/30436 [==============================] - 26s 849us/step - loss: 0.2421 - acc: 0.9056 - val_loss: 0.2358 - val_acc: 0.9032\n",
      "Epoch 5/30\n",
      "30436/30436 [==============================] - 25s 835us/step - loss: 0.2036 - acc: 0.9219 - val_loss: 0.2356 - val_acc: 0.9088\n",
      "Epoch 6/30\n",
      "30436/30436 [==============================] - 25s 820us/step - loss: 0.1751 - acc: 0.9345 - val_loss: 0.2139 - val_acc: 0.9148\n",
      "Epoch 7/30\n",
      "30436/30436 [==============================] - 25s 826us/step - loss: 0.1511 - acc: 0.9436 - val_loss: 0.1905 - val_acc: 0.9243\n",
      "Epoch 8/30\n",
      "30436/30436 [==============================] - 25s 828us/step - loss: 0.1322 - acc: 0.9515 - val_loss: 0.1789 - val_acc: 0.9296\n",
      "Epoch 9/30\n",
      "30436/30436 [==============================] - 25s 826us/step - loss: 0.1179 - acc: 0.9565 - val_loss: 0.1860 - val_acc: 0.9298\n",
      "Epoch 10/30\n",
      "30436/30436 [==============================] - 25s 814us/step - loss: 0.1029 - acc: 0.9621 - val_loss: 0.1929 - val_acc: 0.9340\n",
      "Epoch 11/30\n",
      "30436/30436 [==============================] - 25s 835us/step - loss: 0.0922 - acc: 0.9675 - val_loss: 0.1794 - val_acc: 0.9351\n",
      "Epoch 12/30\n",
      "30436/30436 [==============================] - 25s 823us/step - loss: 0.0797 - acc: 0.9708 - val_loss: 0.2970 - val_acc: 0.9090\n",
      "Epoch 13/30\n",
      "30436/30436 [==============================] - 25s 830us/step - loss: 0.0692 - acc: 0.9758 - val_loss: 0.1810 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 14/30\n",
      "30436/30436 [==============================] - 25s 823us/step - loss: 0.0518 - acc: 0.9822 - val_loss: 0.1971 - val_acc: 0.9377\n",
      "Epoch 15/30\n",
      "30436/30436 [==============================] - 26s 841us/step - loss: 0.0481 - acc: 0.9843 - val_loss: 0.1900 - val_acc: 0.9401\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, rho=0.95)\n",
    "# opt = keras.optimizers.adam(lr=0.0001)\n",
    "model = CNNT5_3D() \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_loss', patience=7),\n",
    "            ReduceLROnPlateau(patience=5, verbose=1)]\n",
    "\n",
    "\n",
    "history = model.fit(x=X_train_range, y=Y_train, epochs=30, validation_data=(X_test_range, Y_test),\n",
    "          batch_size=128, callbacks=callback) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lr', 'val_acc', 'val_loss', 'acc', 'loss'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.DataFrame(columns=['val_acc', 'val_loss', 'train_loss', 'train_acc'])\n",
    "df_logs['val_acc'] =history.history['val_acc']\n",
    "df_logs['val_loss'] = history.history['val_loss']\n",
    "df_logs['train_acc'] = history.history['acc']\n",
    "df_logs['train_loss'] = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs.to_csv('/logs/models/cnnt5_3d_{}.csv'.format(dataset_config), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS = '/SubmitModels/'\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(LOGS+\"cnnt53d_{}.json\".format(dataset_config), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5 \n",
    "model.save_weights(LOGS + 'cnnt53d_{}.h5'.format(dataset_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
